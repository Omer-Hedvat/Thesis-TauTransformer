{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. regular classification - done\n",
    "2. random columns classification - done\n",
    "3. classification using PCA feature reduction - done\n",
    "4. for dist in (wesserstain, hellinger, JM):\n",
    "    1. ranked columns classification (for ranking, use 1st eigen vector from the diffusion maps)        \n",
    "    2. ranked + K-means classification (for ranking, use 1st eigen vector from the diffusion maps)\n",
    "    3. K-mediods classification\n",
    "    4. K-means + pick feature by distance from axis (0, 0)\n",
    "### we want to deploy over all distance functions!\n",
    "    \n",
    "* ask Neta if the ranking we wrote is correct\n",
    "* Chen will write the function regarding the ranking values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classification\n",
    "1. add cross validation k-folds (5-10 folds)\n",
    "2. ranked + K-means: rank by mean row of the flatten matrix. (the bigger the better)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import exp, sqrt, log\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from dictances import jensen_shannon\n",
    "import matplotlib.pyplot as plt\n",
    "from pydiffmap import diffusion_map as dm\n",
    "from pydiffmap.visualization import embedding_plot, data_plot\n",
    "\n",
    "from ref.diffusion_maps import diffusion_mapping\n",
    "from ref.Shir import utils as shir_utils\n",
    "from utils.machine_learning import min_max_scaler\n",
    "from utils.general import calc_mean_std, flatten\n",
    "from utils.distances import norm_by_dist_type, calculate_distance\n",
    "#from main import execute_distance_func, calc_dist, export_heatmaps, k_medoids_features, return_best_features_by_kmeans\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GroupKFold, KFold, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X_train, X_test, y_train, y_test):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    clf = RandomForestClassifier(random_state=1)\n",
    "    multi_target_forest = OneVsRestClassifier(clf, n_jobs=-1)\n",
    "    train_acc = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_train, y_train):\n",
    "        model = multi_target_forest.fit(X_train.iloc[train_index], y_train.iloc[train_index])\n",
    "        train_preds = model.predict(X_train.iloc[test_index])\n",
    "        \n",
    "        train_acc.append(metrics.accuracy_score(y_train.iloc[test_index], train_preds))        \n",
    "    \n",
    "    model = multi_target_forest.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, preds, digits=3))\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/glass.csv')\n",
    "features = data.columns.drop('label')\n",
    "label_column = 'label'\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:333: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.23.2 when using version 1.0.1. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/modules/model_persistence.html#security-maintainability-limitations\n",
      "  self.__class__.__name__, pickle_version, __version__),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.769     0.909     0.833        22\n",
      "           2      0.792     0.760     0.776        25\n",
      "           3      1.000     0.500     0.667         4\n",
      "           5      1.000     0.500     0.667         6\n",
      "           6      0.800     1.000     0.889         4\n",
      "           7      0.909     1.000     0.952        10\n",
      "\n",
      "    accuracy                          0.817        71\n",
      "   macro avg      0.878     0.778     0.797        71\n",
      "weighted avg      0.831     0.817     0.809        71\n",
      "\n",
      "0.7623152709359605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\base.py:439: UserWarning: X has feature names, but RandomForestClassifier was fitted without feature names\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "train_acc = predict(X_train, X_test, y_train, y_test)\n",
    "train_avg_score = sum(train_acc)/len(train_acc)\n",
    "print(f'{train_avg_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install skfeature-chappers\n",
    "from skfeature.function.similarity_based import fisher_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Length of passed values is 1, index implies 9.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-fde9206965bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mranks\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfisher_score\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfisher_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\skfeature\\function\\similarity_based\\fisher_score.py\u001b[0m in \u001b[0;36mfisher_score\u001b[1;34m(X, y, mode)\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mL\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtodense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;31m# compute the numerator of Lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m     \u001b[0mD_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m     \u001b[1;31m# compute the denominator of Lr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mL_prime\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mD\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\common.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[0mother\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitem_from_zerodim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(left, right)\u001b[0m\n\u001b[0;32m    500\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marithmetic_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr_rep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_construct_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mres_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m     \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop_name\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\ops\\__init__.py\u001b[0m in \u001b[0;36m_construct_result\u001b[1;34m(left, result, index, name)\u001b[0m\n\u001b[0;32m    473\u001b[0m     \u001b[1;31m# We do not pass dtype to ensure that the Series constructor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m     \u001b[1;31m#  does inference in the case where `result` has object-dtype.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    290\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    291\u001b[0m                         raise ValueError(\n\u001b[1;32m--> 292\u001b[1;33m                             \u001b[1;34mf\"Length of passed values is {len(data)}, \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m                             \u001b[1;34mf\"index implies {len(index)}.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                         )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of passed values is 1, index implies 9."
     ]
    }
   ],
   "source": [
    "ranks= fisher_score.fisher_score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.633     0.864     0.731        22\n",
      "           2      0.696     0.640     0.667        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      0.667     0.333     0.444         6\n",
      "           6      0.800     1.000     0.889         4\n",
      "           7      1.000     1.000     1.000        10\n",
      "\n",
      "    accuracy                          0.718        71\n",
      "   macro avg      0.633     0.639     0.622        71\n",
      "weighted avg      0.683     0.718     0.690        71\n",
      "\n",
      "0.6650246305418719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "sampled_data = data[features].sample(n=k, axis='columns')\n",
    "new_features = sampled_data.columns\n",
    "sampled_data[label_column] = data[label_column]\n",
    "X_train, X_test, y_train, y_test = train_test_split(sampled_data[new_features], sampled_data[label_column], test_size=0.33, random_state=42)\n",
    "\n",
    "train_acc = predict(X_train, X_test, y_train, y_test)\n",
    "train_avg_score = sum(train_acc)/len(train_acc)\n",
    "print(f'{train_avg_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "# Norm\n",
    "X_train_norm, X_test_norm = min_max_scaler(X_train, features, X_test, False)\n",
    "\n",
    "#PCA\n",
    "pca = PCA(n_components=k)\n",
    "pca.fit(X_train_norm)\n",
    "X_train_pca = pca.transform(X_train_norm)\n",
    "X_test_pca = pca.transform(X_test_norm)\n",
    "y_train_arr = y_train.to_numpy()\n",
    "y_test_arr = y_test.to_numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_np(X_train, X_test, y_train, y_test):\n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "    clf = RandomForestClassifier(random_state=1)\n",
    "    multi_target_forest = OneVsRestClassifier(clf, n_jobs=-1)\n",
    "    train_acc = []\n",
    "    \n",
    "    for train_index, test_index in kf.split(X_train, y_train):\n",
    "        model = multi_target_forest.fit(X_train[train_index], y_train[train_index])\n",
    "        train_preds = model.predict(X_train[test_index])\n",
    "        \n",
    "        train_acc.append(metrics.accuracy_score(y_train[test_index], train_preds))        \n",
    "    \n",
    "    model = multi_target_forest.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(metrics.classification_report(y_test, preds, digits=3))\n",
    "    return train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.720     0.818     0.766        22\n",
      "           2      0.643     0.720     0.679        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      0.600     0.500     0.545         6\n",
      "           6      1.000     0.500     0.667         4\n",
      "           7      0.818     0.900     0.857        10\n",
      "\n",
      "    accuracy                          0.704        71\n",
      "   macro avg      0.630     0.573     0.586        71\n",
      "weighted avg      0.672     0.704     0.681        71\n",
      "\n",
      "0.6568965517241379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_acc = predict_np(X_train_pca, X_test_pca, y_train_arr, y_test_arr)\n",
    "train_avg_score = sum(train_acc)/len(train_acc)\n",
    "print(f'{train_avg_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_norm = min_max_scaler(df, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wasserstein Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "# Norm\n",
    "X_train_norm, X_test_norm = min_max_scaler(X_train, features, X_test)\n",
    "\n",
    "df_dists, dist_dict = calc_dist('wasserstein_dist', X_train_norm, y_train)\n",
    "\n",
    "eps_type='maxmin'#mean' #or maxmin\n",
    "alpha=1\n",
    "vec, egs, coordinates, dataList, epsilon, ranking = (diffusion_mapping(df_dists, alpha, eps_type, 8, 1, dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick feature by distance from axis (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 8 0 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.692     0.818     0.750        22\n",
      "           2      0.714     0.600     0.652        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      0.333     0.333     0.333         6\n",
      "           6      0.375     0.750     0.500         4\n",
      "           7      1.000     0.900     0.947        10\n",
      "\n",
      "    accuracy                          0.662        71\n",
      "   macro avg      0.519     0.567     0.530        71\n",
      "weighted avg      0.656     0.662     0.652        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7241379310344828,\n",
       " 0.7931034482758621,\n",
       " 0.6896551724137931,\n",
       " 0.75,\n",
       " 0.7857142857142857]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = return_farest_featires_from_center(k, coordinates)\n",
    "print(f'{best_features}')\n",
    "predict(X_train.iloc[:, best_features], X_test.iloc[:, best_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ranked columns classification (for ranking, use 1st eigen vector from the diffusion maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 7 1 4 5 6 8 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.655     0.864     0.745        22\n",
      "           2      0.682     0.600     0.638        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      0.400     0.333     0.364         6\n",
      "           6      0.800     1.000     0.889         4\n",
      "           7      1.000     0.800     0.889        10\n",
      "\n",
      "    accuracy                          0.676        71\n",
      "   macro avg      0.589     0.599     0.587        71\n",
      "weighted avg      0.663     0.676     0.662        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4827586206896552,\n",
       " 0.7241379310344828,\n",
       " 0.7931034482758621,\n",
       " 0.6785714285714286,\n",
       " 0.7857142857142857]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_ranking = [item for sublist in ranking for item in sublist]\n",
    "ranking_idx = np.argsort(flat_ranking)\n",
    "print(f'{ranking_idx}')\n",
    "predict(X_train.iloc[:, ranking_idx[-k:]], X_test.iloc[:, ranking_idx[-k:]], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ranked + K-means classification (for ranking, use 1st eigen vector from the diffusion maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 7, 4]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.704     0.864     0.776        22\n",
      "           2      0.750     0.720     0.735        25\n",
      "           3      0.500     0.250     0.333         4\n",
      "           5      1.000     0.500     0.667         6\n",
      "           6      0.333     0.250     0.286         4\n",
      "           7      0.833     1.000     0.909        10\n",
      "\n",
      "    accuracy                          0.732        71\n",
      "   macro avg      0.687     0.597     0.618        71\n",
      "weighted avg      0.731     0.732     0.718        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6896551724137931,\n",
       " 0.6896551724137931,\n",
       " 0.6551724137931034,\n",
       " 0.6428571428571429,\n",
       " 0.6428571428571429]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "\n",
    "best_features, labels, features_rank = return_best_features_by_kmeans(coordinates, k)\n",
    "print(f'{best_features}')\n",
    "predict(X_train.iloc[:, best_features], X_test.iloc[:, best_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-mediods classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 5, 6, 8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.607     0.773     0.680        22\n",
      "           2      0.696     0.640     0.667        25\n",
      "           3      0.500     0.250     0.333         4\n",
      "           5      1.000     0.333     0.500         6\n",
      "           6      0.667     0.500     0.571         4\n",
      "           7      0.769     1.000     0.870        10\n",
      "\n",
      "    accuracy                          0.676        71\n",
      "   macro avg      0.706     0.583     0.603        71\n",
      "weighted avg      0.692     0.676     0.661        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5862068965517241,\n",
       " 0.6551724137931034,\n",
       " 0.4482758620689655,\n",
       " 0.6785714285714286,\n",
       " 0.6428571428571429]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "k_features = k_medoids_features(coordinates, k)\n",
    "print(f'{k_features}')\n",
    "predict(X_train.iloc[:, k_features], X_test.iloc[:, k_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JM Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "# Norm\n",
    "X_train_norm, X_test_norm = min_max_scaler(X_train, features, X_test)\n",
    "\n",
    "df_dists, dist_dict = calc_dist('jm_dist', X_train_norm, y_train)\n",
    "eps_type='maxmin'#mean' #or maxmin\n",
    "alpha=1\n",
    "vec, egs, coordinates, dataList, epsilon, ranking = (diffusion_mapping(df_dists, alpha, eps_type, 8, 1, dim=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick feature by distance from axis (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 5 8 7]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.655     0.864     0.745        22\n",
      "           2      0.640     0.640     0.640        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      0.333     0.167     0.222         6\n",
      "           6      0.800     1.000     0.889         4\n",
      "           7      1.000     0.900     0.947        10\n",
      "\n",
      "    accuracy                          0.690        71\n",
      "   macro avg      0.571     0.595     0.574        71\n",
      "weighted avg      0.642     0.690     0.659        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7241379310344828,\n",
       " 0.6206896551724138,\n",
       " 0.7241379310344828,\n",
       " 0.5,\n",
       " 0.6071428571428571]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = return_farest_featires_from_center(k, coordinates)\n",
    "print(f'{best_features}')\n",
    "predict(X_train.iloc[:, best_features], X_test.iloc[:, best_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ranked columns classification (for ranking, use 1st eigen vector from the diffusion maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 5 8 2 1 3 6 4 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.741     0.909     0.816        22\n",
      "           2      0.818     0.720     0.766        25\n",
      "           3      0.667     0.500     0.571         4\n",
      "           5      0.750     0.500     0.600         6\n",
      "           6      0.750     0.750     0.750         4\n",
      "           7      0.909     1.000     0.952        10\n",
      "\n",
      "    accuracy                          0.789        71\n",
      "   macro avg      0.772     0.730     0.743        71\n",
      "weighted avg      0.789     0.789     0.782        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7586206896551724,\n",
       " 0.4827586206896552,\n",
       " 0.8620689655172413,\n",
       " 0.7142857142857143,\n",
       " 0.8214285714285714]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_ranking = [item for sublist in ranking for item in sublist]\n",
    "ranking_idx = np.argsort(flat_ranking)\n",
    "print(f'{ranking_idx}')\n",
    "predict(X_train.iloc[:, ranking_idx[-k:]], X_test.iloc[:, ranking_idx[-k:]], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ranked + K-means classification (for ranking, use 1st eigen vector from the diffusion maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 5, 2, 3]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.720     0.818     0.766        22\n",
      "           2      0.704     0.760     0.731        25\n",
      "           3      1.000     0.250     0.400         4\n",
      "           5      1.000     0.333     0.500         6\n",
      "           6      0.750     0.750     0.750         4\n",
      "           7      0.833     1.000     0.909        10\n",
      "\n",
      "    accuracy                          0.746        71\n",
      "   macro avg      0.835     0.652     0.676        71\n",
      "weighted avg      0.771     0.746     0.730        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5862068965517241,\n",
       " 0.6551724137931034,\n",
       " 0.6896551724137931,\n",
       " 0.6071428571428571,\n",
       " 0.6428571428571429]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "best_features, labels, features_rank = return_best_features_by_kmeans(coordinates, k)\n",
    "print(f'{best_features}')\n",
    "predict(X_train.iloc[:, best_features], X_test.iloc[:, best_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-mediods classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 3, 4, 8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.720     0.818     0.766        22\n",
      "           2      0.667     0.720     0.692        25\n",
      "           3      0.500     0.250     0.333         4\n",
      "           5      0.667     0.333     0.444         6\n",
      "           6      0.500     0.250     0.333         4\n",
      "           7      0.667     0.800     0.727        10\n",
      "\n",
      "    accuracy                          0.676        71\n",
      "   macro avg      0.620     0.529     0.549        71\n",
      "weighted avg      0.664     0.676     0.659        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6551724137931034,\n",
       " 0.7586206896551724,\n",
       " 0.6896551724137931,\n",
       " 0.6785714285714286,\n",
       " 0.5714285714285714]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "k_features = k_medoids_features(coordinates, k)\n",
    "print(f'{k_features}')\n",
    "predict(X_train.iloc[:, k_features], X_test.iloc[:, k_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hellinger Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "# Norm\n",
    "X_train_norm, X_test_norm = min_max_scaler(X_train, features, X_test)\n",
    "\n",
    "df_dists, dist_dict = calc_dist('hellinger_dist', X_train_norm, y_train)\n",
    "\n",
    "eps_type='maxmin'#mean' #or maxmin\n",
    "alpha=1\n",
    "vec, egs, coordinates, dataList, epsilon, ranking = (diffusion_mapping(df_dists, alpha, eps_type, 8, 1, dim=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.argsort(coordinates[0]) == np.argsort(df_dists.mean(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 7, 5, 1, 3, 4, 6, 0, 8], dtype=int64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(coordinates[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = [1 ,4,5,6]\n",
    "#b = [2 ,4,5,6]\n",
    "#sum(a==b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    6\n",
       "3    4\n",
       "4    3\n",
       "5    5\n",
       "6    7\n",
       "7    8\n",
       "8    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(df_dists.mean(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pick feature by distance from axis (0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 8 7 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.731     0.864     0.792        22\n",
      "           2      0.760     0.760     0.760        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      1.000     0.333     0.500         6\n",
      "           6      0.571     1.000     0.727         4\n",
      "           7      0.909     1.000     0.952        10\n",
      "\n",
      "    accuracy                          0.761        71\n",
      "   macro avg      0.662     0.659     0.622        71\n",
      "weighted avg      0.739     0.761     0.730        71\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\chenb\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7586206896551724,\n",
       " 0.6896551724137931,\n",
       " 0.7241379310344828,\n",
       " 0.6785714285714286,\n",
       " 0.7857142857142857]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_features = return_farest_featires_from_center(k, coordinates)\n",
    "print(f'{best_features}')\n",
    "predict(X_train.iloc[:, best_features], X_test.iloc[:, best_features], y_train, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ranked columns classification (for ranking, use 1st eigen vector from the diffusion maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8 7 5 3 0 6 4 1 2]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.682     0.682     0.682        22\n",
      "           2      0.654     0.680     0.667        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      1.000     0.667     0.800         6\n",
      "           6      0.250     0.250     0.250         4\n",
      "           7      0.643     0.900     0.750        10\n",
      "\n",
      "    accuracy                          0.648        71\n",
      "   macro avg      0.538     0.530     0.525        71\n",
      "weighted avg      0.631     0.648     0.633        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6206896551724138,\n",
       " 0.6206896551724138,\n",
       " 0.6896551724137931,\n",
       " 0.5,\n",
       " 0.6071428571428571]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flat_ranking = [item for sublist in ranking for item in sublist]\n",
    "ranking_idx = np.argsort(flat_ranking)\n",
    "print(f'{ranking_idx}')\n",
    "predict(X_train.iloc[:, ranking_idx[-k:]], X_test.iloc[:, ranking_idx[-k:]], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ranked + K-means classification (for ranking, use 1st eigen vector from the diffusion maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2, 7, 5, 8]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.692     0.818     0.750        22\n",
      "           2      0.654     0.680     0.667        25\n",
      "           3      1.000     0.250     0.400         4\n",
      "           5      1.000     0.333     0.500         6\n",
      "           6      0.667     1.000     0.800         4\n",
      "           7      1.000     1.000     1.000        10\n",
      "\n",
      "    accuracy                          0.732        71\n",
      "   macro avg      0.835     0.680     0.686        71\n",
      "weighted avg      0.764     0.732     0.718        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5172413793103449,\n",
       " 0.6206896551724138,\n",
       " 0.4827586206896552,\n",
       " 0.39285714285714285,\n",
       " 0.6071428571428571]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "\n",
    "best_features, labels, features_rank = return_best_features_by_kmeans(coordinates, k)\n",
    "print(f'{best_features}')\n",
    "predict(X_train.iloc[:, best_features], X_test.iloc[:, best_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-mediods classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 4, 5]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1      0.593     0.727     0.653        22\n",
      "           2      0.577     0.600     0.588        25\n",
      "           3      0.000     0.000     0.000         4\n",
      "           5      0.500     0.167     0.250         6\n",
      "           6      0.667     0.500     0.571         4\n",
      "           7      0.667     0.800     0.727        10\n",
      "\n",
      "    accuracy                          0.592        71\n",
      "   macro avg      0.500     0.466     0.465        71\n",
      "weighted avg      0.560     0.592     0.565        71\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6896551724137931,\n",
       " 0.6551724137931034,\n",
       " 0.6551724137931034,\n",
       " 0.75,\n",
       " 0.4642857142857143]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[features], data[label_column], test_size=0.33, random_state=42)\n",
    "\n",
    "k_features = k_medoids_features(coordinates, k)\n",
    "print(f'{k_features}')\n",
    "predict(X_train.iloc[:, k_features], X_test.iloc[:, k_features], y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
